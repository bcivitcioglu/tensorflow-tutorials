{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0960b000-5f5c-41e9-b9f2-2d794fd0ac74",
   "metadata": {},
   "source": [
    "<h1>TensorFlow Model Building Tutorial</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707be7c1-75c9-4104-8e62-9213c69aadd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/burakcivitcioglu/Documents/machine_learning/ising/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd /Users/burakcivitcioglu/Documents/machine_learning/ising/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9144fb0e-a06f-40a7-a100-c2db1f3540db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d78c0f6-1bfe-4b7c-8660-ce71882a0817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.4.1\n",
      "TensorBoard version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "print(\"TensorBoard version: \", tensorboard.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db60cf-ffd6-4a38-92bc-930ec5ee369b",
   "metadata": {},
   "source": [
    "<h2>We will define the same simple CNN using Sequential API, Functional API and finally, the aim of this notebook, we will build it with Subclassing API.</h2>\n",
    "<p>We apply it to the same MNIST data for educational purposes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faffecba-5174-40c3-875e-10a03cd842cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shapes\n",
      "x:  (60000, 28, 28) y: (60000,)\n",
      "Test Shapes\n",
      "x: (10000, 28, 28) y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(\"Training Shapes\")\n",
    "print('x: ',x_train.shape, 'y:',y_train.shape)\n",
    "print(\"Test Shapes\")\n",
    "print('x:',x_test.shape,'y:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed91c56-d19e-4ee1-a20e-d9517c61c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Expanding Dimensions is so that we can easily apply it with a CNN\n",
    "# Since MNIST data is greyscale, it has 1 channel. We expand the dimension and \n",
    "# repeat the x_train 3 times across 3 channels so that it will be acted as if\n",
    "# it's an RGB image.\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_train = np.repeat(x_train, 3, axis=-1)\n",
    "x_train = x_train / 255\n",
    "# train set / target \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "\n",
    "# validation set / data \n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "x_test = np.repeat(x_test, 3, axis=-1)\n",
    "x_test = x_test/ 255\n",
    "# validation set / target \n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a277e5e9-23d1-49d5-809a-af4dfae2d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shapes\n",
      "x:  (60000, 28, 28, 3) y: (60000, 10)\n",
      "Test Shapes\n",
      "x: (10000, 28, 28, 3) y: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shapes\")\n",
    "print('x: ',x_train.shape, 'y:',y_train.shape)\n",
    "print(\"Test Shapes\")\n",
    "print('x:',x_test.shape,'y:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e32485c-0c9f-4947-85c3-8885a15091f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_tuple = (28,28,3)\n",
    "input_dim = tf.keras.Input(shape=(input_dim_tuple))\n",
    "\n",
    "output_dim = (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b128490-1673-4faa-baa6-068d89c84255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 28, 28, 3) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb22fd-0a47-4e85-aa5b-e56b8356fe38",
   "metadata": {},
   "source": [
    "<h3>Sequential API</h3>\n",
    "<p>We use the tf.keras sequential method and then use the add() method to keep adding layers. With this method we can only connect one layer to the next, sequentially as the name suggests. It is not flexible and it is not customizable. Convenient for quick prototyping.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52258d83-274a-483b-9c52-6f75ead42a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initiate the sequential model and we add the input layer\n",
    "\n",
    "seq_model = tf.keras.Sequential(name = \"Sequential\")\n",
    "seq_model.add(tf.keras.Input(shape=input_dim_tuple))\n",
    "\n",
    "# Block 1: First block of convolutional layer and the follow ups\n",
    "\n",
    "seq_model.add(tf.keras.layers.Conv2D(32, 3, strides=2, activation=\"relu\"))\n",
    "seq_model.add(tf.keras.layers.MaxPooling2D(3))\n",
    "seq_model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Block 2\n",
    "\n",
    "seq_model.add(tf.keras.layers.Conv2D(64, 3, activation=\"relu\"))\n",
    "seq_model.add(tf.keras.layers.BatchNormalization())\n",
    "seq_model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "# Now that we apply global max pooling.\n",
    "\n",
    "seq_model.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "\n",
    "seq_model.add(tf.keras.layers.Dense(output_dim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8fe86-9d3d-4422-be34-36c910957216",
   "metadata": {},
   "source": [
    "<h3>Functional API Implementation of the same model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e75d95cc-ee62-4c99-9758-285ef6b0c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare input shape \n",
    "input = tf.keras.Input(shape=(input_dim_tuple))\n",
    "\n",
    "# Block 1\n",
    "conv = tf.keras.layers.Conv2D(32, 3, strides=2, activation=\"relu\")\n",
    "x = conv(input)\n",
    "\n",
    "# Then we continue adding layers as we please\n",
    "\n",
    "x = tf.keras.layers.MaxPooling2D(3)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "# Block 2\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "# Now that we apply global max pooling.\n",
    "gap = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "output = tf.keras.layers.Dense(output_dim)(gap)\n",
    "\n",
    "# bind all\n",
    "func_model = tf.keras.Model(input, output, name = \"Functional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54add5aa-9e74-46fe-aba6-1c1e35233a90",
   "metadata": {},
   "source": [
    "<h3>Subclassing API</h3>\n",
    "<p>In Subclassing we will always have two methods. '__init__' and 'call' where the former will be the definitions of the layers as instance attributes, and the ladder will be the way we connect these layers when called.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "872e77db-d023-4d1d-9e03-399784f253af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSubClassing(tf.keras.Model):\n",
    "    def __init__(self, output_dim):\n",
    "        super(ModelSubClassing, self).__init__()\n",
    "        # define all layers in init\n",
    "        # Layer of Block 1\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, strides=2, activation=\"relu\")\n",
    "        self.max1  = tf.keras.layers.MaxPooling2D(3)\n",
    "        self.bn1   = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        # Layer of Block 2\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")\n",
    "        self.bn2   = tf.keras.layers.BatchNormalization()\n",
    "        self.drop  = tf.keras.layers.Dropout(0.3)\n",
    "\n",
    "        # GAP, followed by Classifier\n",
    "        self.gap   = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "\n",
    "    def call(self, input_shape, training=False):\n",
    "        # forward pass: block 1 \n",
    "        x = self.conv1(input_shape)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # forward pass: block 2 \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # droput followed by gap and classifier\n",
    "        x = self.drop(x)\n",
    "        x = self.gap(x)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7222d355-866e-412a-9665-740c23117475",
   "metadata": {},
   "source": [
    "<h3>Now let's run all three for the data we have</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b59cb835-e40b-4e5d-a3e9-409e3709ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential API\n",
      "\n",
      "Functional API\n",
      "\n",
      "Model Sub-Classing API\n"
     ]
    }
   ],
   "source": [
    "# compile \n",
    "print('Sequential API')\n",
    "seq_model.compile(\n",
    "          loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
    "          metrics   = tf.keras.metrics.CategoricalAccuracy(),\n",
    "          optimizer = tf.keras.optimizers.Adam())\n",
    "# fit \n",
    "\n",
    "\n",
    "\n",
    "# compile \n",
    "print('\\nFunctional API')\n",
    "func_model.compile(\n",
    "          loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
    "          metrics   = tf.keras.metrics.CategoricalAccuracy(),\n",
    "          optimizer = tf.keras.optimizers.Adam())\n",
    "# fit \n",
    "\n",
    "\n",
    "\n",
    "# compile \n",
    "print('\\nModel Sub-Classing API')\n",
    "sub_classing_model = ModelSubClassing(output_dim)\n",
    "sub_classing_model.compile(\n",
    "          loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
    "          metrics   = tf.keras.metrics.CategoricalAccuracy(),\n",
    "          optimizer = tf.keras.optimizers.Adam())\n",
    "# fit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e7a2d8e-66de-4e9c-b637-ea1cac043154",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=\"/Users/burakcivitcioglu/Documents/machine_learning/ising/notebooks/logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c8ec88-a81a-4e51-98de-59f5a409addf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 7ms/step - loss: 7.0395 - categorical_accuracy: 0.1900\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 7.0847 - categorical_accuracy: 0.1457\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 6.7059 - categorical_accuracy: 0.1350\n"
     ]
    }
   ],
   "source": [
    "seq_model.fit(x_train, y_train, batch_size=128, epochs=1,callbacks=[tensorboard_callback])\n",
    "func_model.fit(x_train, y_train, batch_size=128, epochs=1)\n",
    "sub_classing_model.fit(x_train, y_train, batch_size=128, epochs=1);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02345c-71ff-4616-abc8-d66fcb72729d",
   "metadata": {},
   "source": [
    "<h3>Let's see how the 3 are the same model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b4e23ed-6d84-4efa-89d1-ce56de1a402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 13, 13, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 20,426\n",
      "Trainable params: 20,234\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Model: \"Functional\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 28, 28, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 20,426\n",
      "Trainable params: 20,234\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Model: \"model_sub_classing\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            multiple                  896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  650       \n",
      "=================================================================\n",
      "Total params: 20,426\n",
      "Trainable params: 20,234\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()\n",
    "func_model.summary()\n",
    "sub_classing_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "151ae0ff-e3b2-4d6a-8b5c-d753a506ca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-77f0ef763c6dcb73\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-77f0ef763c6dcb73\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "464bec39-a6d7-4cd2-9229-be6b17189e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/burakcivitcioglu/Documents/machine_learning/ising/notebooks'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a046b-e2a7-4405-bf1f-9f0811e720a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
